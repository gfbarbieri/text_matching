{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words Text Matching Example\n",
    "\n",
    "This notebook demonstrates how to use the BOWPredictor for text matching using bag-of-words approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "## FOR NOTEBOOKS ONLY: ADD THE PROJECT ROOT TO THE PYTHON PATH\n",
    "########################################################################\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(\n",
    "    0, os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score, accuracy_score\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from text_prediction.predictors.vectorized.bow import BOWPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n",
    "\n",
    "For this example, we'll use a sample dataset of product names and their variations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iphone 13 pro max</td>\n",
       "      <td>iPhone 13 Pro Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iphone 13 promax</td>\n",
       "      <td>iPhone 13 Pro Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iphone 13 pro</td>\n",
       "      <td>iPhone 13 Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iphone 13</td>\n",
       "      <td>iPhone 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samsung galaxy s21</td>\n",
       "      <td>Samsung Galaxy S21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    X              y_true\n",
       "0   iphone 13 pro max   iPhone 13 Pro Max\n",
       "1    iphone 13 promax   iPhone 13 Pro Max\n",
       "2       iphone 13 pro       iPhone 13 Pro\n",
       "3           iphone 13           iPhone 13\n",
       "4  samsung galaxy s21  Samsung Galaxy S21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/product_descriptions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Text Search\n",
    "\n",
    "In this example, we have a large set of text data and we simply want to seach for instances of a certain query. For example, in a list of reported survey responses, we want to look for instances of \"iPhone 13 Pro Max\" in our data.\n",
    "\n",
    "Let's start by creating a basic BOWPredictor with with a char_wb analyzer and we will split it into 3-grams. This is a n-gram approach, where n is the number of characters in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = BOWPredictor(analyzer=\"char_wb\", ngram_range=(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To similulate this type of search, we will fit the predictor only on the X, which resemble the survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 2133 stored elements and shape (134, 729)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_transform(X=df['X'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will search our survey responses for the product \"iPhone 13 Pro Max\". We can see that there about 4 likely instances, but only two of them contain the product name. In a production framework, you would do more to clean up the text data before you search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('iphone 13 pro max', np.float64(0.9999999999999999)),\n",
       "  ('iphone 13 pro', np.float64(0.8864052604279182)),\n",
       "  ('iphone 13 promax', np.float64(0.8571428571428571)),\n",
       "  ('iphone 13', np.float64(0.7559289460184545)),\n",
       "  ('macbook pro m1 max', np.float64(0.45374260648651504)),\n",
       "  ('macbook pro m1', np.float64(0.3086066999241839)),\n",
       "  ('macbook m1 pro', np.float64(0.3086066999241839)),\n",
       "  ('airpods pro 2', np.float64(0.24174688920761409)),\n",
       "  ('galaxy buds pro', np.float64(0.22237479499833038)),\n",
       "  ('samsung buds pro', np.float64(0.2142857142857143)),\n",
       "  ('airpods pro 2nd gen', np.float64(0.2004459314343183)),\n",
       "  ('airpods pro second generation', np.float64(0.15724272550828777)),\n",
       "  ('honey nut cheerios', np.float64(0.1336306209562122)),\n",
       "  ('progresso chicken noodle', np.float64(0.11396057645963795)),\n",
       "  ('coke zero', np.float64(0.0944911182523068)),\n",
       "  ('macbook m1', np.float64(0.0890870806374748)),\n",
       "  ('pepsi zero sugar', np.float64(0.07142857142857144))]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_proba(X=\"iPhone 13 Pro Max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned a number of possible matches, with a score for each match. The score is the cosine similarity between the query and the product description. We could set the limit to say the top 5 matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('iphone 13 pro max', np.float64(0.9999999999999999)),\n",
       "  ('iphone 13 pro', np.float64(0.8864052604279182)),\n",
       "  ('iphone 13 promax', np.float64(0.8571428571428571)),\n",
       "  ('iphone 13', np.float64(0.7559289460184545))]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.limit = 4\n",
    "predictor.predict_proba(X=\"iPhone 13 Pro Max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Classification Example\n",
    "\n",
    "Let's assume you're trying to label a batch of survey responses, instead of searching the existence of some query. For example, let's say we are trying to standardize the responses using the training data provided. You could use the BOWPredictor to predict the label for each survey response.\n",
    "\n",
    "This resembles a supervised learning problem where we have a set of features (X) and a set of labels (y). We can fit the BOWPredictor on the training data and then use it to predict the label for each survey response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 2159 stored elements and shape (101, 785)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_transform(X=df['X'].tolist(), y=df['y_true'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.str_('iPhone 13 Pro Max'), np.str_('iPhone 13 Pro'), np.str_('iPhone 13')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that 'iphone 12' is not in the labeled data, so we cannot\n",
    "# predict it.\n",
    "predictor.predict(X=['iphone 13 pro max', 'iphone 13 pro', 'iphone 12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Clustering Example\n",
    "\n",
    "Let's assume you're trying to cluster a batch of survey responses. You could use the BOWPredictor to cluster the survey responses.\n",
    "\n",
    "This resembles an unsupervised learning problem where we have a set of features (X) and we want to cluster the data into different groups. We can fit the BOWPredictor on the training data and then use it to cluster the survey responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 2133 stored elements and shape (134, 729)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_transform(X=df['X'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first survey response and see what cluster it belongs to by seeing which values have the highest probability, which will always include itself. A score cutoff could be applied to simluate cluster assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('iphone 13 pro max', np.float64(0.9999999999999999)),\n",
       "  ('iphone 13 pro', np.float64(0.8864052604279182)),\n",
       "  ('iphone 13 promax', np.float64(0.8571428571428571)),\n",
       "  ('iphone 13', np.float64(0.7559289460184545))]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict_proba(X=df['X'].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validate Performance\n",
    "\n",
    "Let's validate the performance of the BOWPredictor as a classifier (supervised learning). We can create several version of the BOWPredictor with different parameters and validate their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Grid Search\n",
    "\n",
    "Since the BOW predictor is not a true learner, it doens't make sense to use a grid search with cross validation. Instead, we can manually create a list of BOWPredictor with different parameters and validate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Let's create a list of all the BOWPredictor with different parameters.\n",
    "params = [\n",
    "    {\"analyzer\": \"word\", \"ngram_range\": (1, 1)},\n",
    "    {\"analyzer\": \"word\", \"ngram_range\": (1, 2)},\n",
    "    {\"analyzer\": \"char_wb\", \"ngram_range\": (1, 2)},\n",
    "    {\"analyzer\": \"char_wb\", \"ngram_range\": (1, 3)},\n",
    "    {\"analyzer\": \"char_wb\", \"ngram_range\": (2, 3)},\n",
    "    {\"analyzer\": \"char_wb\", \"ngram_range\": (2, 4)},\n",
    "]\n",
    "\n",
    "# Create a list of all the BOWPredictor with different parameters.\n",
    "all_predictors = [BOWPredictor(**params) for params in params]\n",
    "print(len(all_predictors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analyzer</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>char_wb</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>0.9552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>char_wb</td>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>char_wb</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>0.9323</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>0.9403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>char_wb</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.9328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.8868</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.9030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>word</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.8955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Analyzer  ngrams  F1 Score  Precision  Recall  Accuracy\n",
       "3  char_wb  (1, 3)    0.9488     0.9590  0.9552    0.9552\n",
       "4  char_wb  (2, 3)    0.9423     0.9577  0.9478    0.9478\n",
       "5  char_wb  (2, 4)    0.9323     0.9465  0.9403    0.9403\n",
       "2  char_wb  (1, 2)    0.9229     0.9347  0.9328    0.9328\n",
       "1     word  (1, 2)    0.8868     0.9005  0.9030    0.9030\n",
       "0     word  (1, 1)    0.8739     0.8818  0.8955    0.8955"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty list to store results.\n",
    "results = []\n",
    "\n",
    "for predictor in all_predictors:\n",
    "\n",
    "    # Fit the predictor on the product descriptions.\n",
    "    predictor.fit_transform(X=df['X'].tolist(), y=df['y_true'].tolist())\n",
    "    \n",
    "    # Predict the product descriptions.\n",
    "    predictions = predictor.predict(X=df['X'].tolist())\n",
    "    \n",
    "    # Store results in a dictionary.\n",
    "    result = {\n",
    "        'Analyzer': predictor.analyzer,\n",
    "        'ngrams': predictor.ngram_range,\n",
    "        'F1 Score': f1_score(df['y_true'], predictions, average='weighted'),\n",
    "        'Precision': precision_score(df['y_true'], predictions, average='weighted', zero_division=0),\n",
    "        'Recall': recall_score(df['y_true'], predictions, average='weighted'),\n",
    "        'Accuracy': accuracy_score(df['y_true'], predictions)\n",
    "    }\n",
    "    \n",
    "    # Append to results list.\n",
    "    results.append(result)\n",
    "\n",
    "# Convert to DataFrame.\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Round numeric columns to 4 decimal places.\n",
    "numeric_columns = ['F1 Score', 'Precision', 'Recall', 'Accuracy']\n",
    "results_df[numeric_columns] = results_df[numeric_columns].round(4)\n",
    "\n",
    "# Sort the results by F1 Score in descending order.\n",
    "results_df.sort_values(by='F1 Score', ascending=False, inplace=True)\n",
    "\n",
    "# Display the results.\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Validation with Grid Search\n",
    "\n",
    "However, the predictor can theoretically be plugged into an existing grid search pipeline without causing errors. It follows the sklearn estimator API, so it can be used in a grid search pipeline.\n",
    "\n",
    "One work-around is to define the CV such that it uses the same folds for each parameter combination. To do that, we pass a CV value where the indexes are the same for both test and train datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    BOWPredictor(),\n",
    "    {\n",
    "        'analyzer': ['char_wb'],\n",
    "        'ngram_range': [\n",
    "            (1, 2), (1, 3), (2, 3), (2, 4)\n",
    "        ]\n",
    "    },\n",
    "    cv=[(np.arange(len(df)), np.arange(len(df)))],\n",
    "    scoring='f1_weighted',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'analyzer': 'char_wb', 'ngram_range': (1, 3)}\n",
      "Best score: 0.9487562189054726\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'analyzer': 'char_wb', 'ngram_range': (1, 3)}</td>\n",
       "      <td>0.948756</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'analyzer': 'char_wb', 'ngram_range': (2, 3)}</td>\n",
       "      <td>0.942289</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'analyzer': 'char_wb', 'ngram_range': (2, 4)}</td>\n",
       "      <td>0.932338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'analyzer': 'char_wb', 'ngram_range': (1, 2)}</td>\n",
       "      <td>0.922921</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           params  mean_test_score  \\\n",
       "1  {'analyzer': 'char_wb', 'ngram_range': (1, 3)}         0.948756   \n",
       "2  {'analyzer': 'char_wb', 'ngram_range': (2, 3)}         0.942289   \n",
       "3  {'analyzer': 'char_wb', 'ngram_range': (2, 4)}         0.932338   \n",
       "0  {'analyzer': 'char_wb', 'ngram_range': (1, 2)}         0.922921   \n",
       "\n",
       "   std_test_score  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "0             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the grid search.\n",
    "grid_search.fit(df['X'].tolist(), df['y_true'].tolist())\n",
    "\n",
    "# Print results.\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Get detailed results in a DataFrame.\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "results = results.sort_values('rank_test_score')\n",
    "display(results[['params', 'mean_test_score', 'std_test_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-search-0Fhw7W71-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
